{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coregvy/Con4AI/blob/master/handson1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1QRBFQZpK1J"
      },
      "source": [
        "# コネクトフォー の ゲームAIを作ろう"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-1Be_bkrYOi"
      },
      "source": [
        "## AI環境の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wgTmOfB3vjx"
      },
      "source": [
        "### tensorflow 1.x インストール\n",
        "tensorflow 1系はColabで使えなくなったので、強制的にインストールする\\\n",
        "参考：https://qiita.com/katoyu_try1/items/0228870c41d9ac54e6e9\n",
        "\n",
        "将来的には Stable Baselines3に対応するよう改修予定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "fVjSUJ_DrtED",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "b95478ab-21c8-45bd-ba65-c7062c358600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r0% [Connecting to archive.ubuntu.com] [Connecting to security.ubuntu.com (185.1\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Connecting to\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [98.9 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [992 kB]\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,472 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,267 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,216 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,133 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,554 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,226 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,040 kB]\n",
            "Fetched 17.6 MB in 6s (2,894 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libopenmpi-dev is already the newest version (2.1.1-8).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2.2).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y -q cmake libopenmpi-dev zlib1g-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "cBgnKD--wZfg",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "54e5497a-e447-417d-daed-51e04cee05ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev xvfb\n",
            "0 upgraded, 3 newly installed, 0 to remove and 28 not upgraded.\n",
            "Need to get 982 kB of archives.\n",
            "After this operation, 3,350 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3 amd64 2.8.1-3 [73.6 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 freeglut3-dev amd64 2.8.1-3 [124 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.11 [785 kB]\n",
            "Fetched 982 kB in 0s (2,628 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 123942 files and directories currently installed.)\n",
            "Preparing to unpack .../freeglut3_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../freeglut3-dev_2.8.1-3_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../xvfb_2%3a1.19.6-1ubuntu4.11_amd64.deb ...\n",
            "Unpacking xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-3) ...\n",
            "Setting up xvfb (2:1.19.6-1ubuntu4.11) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-3) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y -q ffmpeg freeglut3-dev xvfb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "YTUCc5KnpBtQ",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "544291d7-1c7a-4c2d-8713-04ed7d520f6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 410.9 MB 31 kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 503 kB 51.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.9 MB/s \n",
            "\u001b[?25h  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 1.15.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 1.15.1 which is incompatible.\n",
            "tensorflow-probability 0.16.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-gpu==1.15.2 --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZUwAa-iHdU0"
      },
      "source": [
        "### ライブラリのインストール\n",
        "\n",
        "MPIは並列処理のライブラリです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "Wp4S_sOXrbE3",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "outputId": "563d4100-c6f2-49be-faab-288fc45c136e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 240 kB 49.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 721 kB 67.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 719 kB 49.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 710 kB 48.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 732 kB 41.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 720 kB 48.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 696 kB 55.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 694 kB 53.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 626 kB 60.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 624 kB 61.9 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 631 kB 59.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 32.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 966 kB 68.8 MB/s \n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'atari-py' candidate (version 0.2.6 at https://files.pythonhosted.org/packages/8f/ba/1d22e9d2f332f07aaa57041f5dd569c2cb40a92bd6374a0b743ec3dfae97/atari_py-0.2.6-cp37-cp37m-manylinux1_x86_64.whl#sha256=d9e2c25d39783867c2f29d1dd9d3a659fc56036456d07dc9efe8bd7bb31a07d7 (from https://pypi.org/simple/atari-py/))\n",
            "Reason for being yanked: re-release with new wheels\u001b[0m\n",
            "\u001b[?25h  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#!python3.7\n",
        "!pip install gym==0.19.0 stable-baselines==2.10.2 --quiet\n",
        "# !pip install stable-baselines[mpi] --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AwgYeU5yrSP"
      },
      "source": [
        "### Dependencis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8kzRZXbVyrSQ",
        "outputId": "c61b96c5-0e1c-4522-bce6-591acd2a0213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/stable_baselines/__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
            "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
          ]
        }
      ],
      "source": [
        "#!python3.7\n",
        "import tensorflow as tf;\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import gym\n",
        "# from stable_baselines.common.policies import MlpPolicy\n",
        "from stable_baselines import PPO2\n",
        "\n",
        "import warnings\n",
        "\n",
        "# https://stackoverflow.com/questions/15777951/how-to-suppress-pandas-future-warning\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "tf.get_logger().setLevel('INFO')\n",
        "tf.autograph.set_verbosity(0)\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9JXDhtyrSR"
      },
      "source": [
        "+ tensorflow のインストール確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vi286tCfyrSR",
        "outputId": "d3fba848-f328-47e3-d5bc-375a78e5ede3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Sum:0\", shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf;\n",
        "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl-CANTcyrSS"
      },
      "source": [
        "## 簡単なゲームでAIを学ぶ\n",
        "\n",
        "上下左右に移動して、ゴールを目指すゲームという簡単なルールのゲームを通して、[StableBaselines](https://stable-baselines.readthedocs.io/en/master/index.html) / [OpenAI Gym](https://github.com/openai/gym) を使ったゲームAIの作り方を学んでいきます。\n",
        "\n",
        "### ゲームルール\n",
        "\n",
        "以下のような入力を与えます\n",
        "```\n",
        ".......\n",
        ".......\n",
        "..P....\n",
        ".......\n",
        ".......\n",
        ".....G.\n",
        ".......\n",
        "```\n",
        "7x7マスに `P` (Player) の位置から `G` (Goal) に向けて移動するゲームです。\n",
        "出力には\n",
        "\n",
        "- 0: 上\n",
        "- 1: 右\n",
        "- 2: 下\n",
        "- 3: 左\n",
        "\n",
        "に移動します。枠外に出てしまった場合は失敗です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vknDNaoLyrSS"
      },
      "source": [
        "### 環境クラス\n",
        "\n",
        "ゲームのルールにあわせた、環境クラスを作成します。\\\n",
        "環境クラスでは以下のメソッドを定義する必要があります。\n",
        "* reset：状態を初期化します\n",
        "* step：次の行動を入力として、一つステップを進める関数を作成します。報酬の計算も行います。\n",
        "* render：現在の状態を描画します。中身は適当で大丈夫です\n",
        "\n",
        "また、以下の変数をコンストラクタで定義する必要があります。\n",
        "* action_space：実際の行動の数を設定\n",
        "* self.observation_space：状態空間の定義\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fHlybnBfyrSS"
      },
      "outputs": [],
      "source": [
        "class Dist(gym.Env):\n",
        "  MAX_X = 7\n",
        "  MAX_Y = 7\n",
        "  ACTION_TOP = 0\n",
        "  ACTION_RIGHT = 1\n",
        "  ACTION_BOTTOM = 2\n",
        "  ACTION_LEFT = 3\n",
        "  PRE = [0,0,0]\n",
        "  ACTION_MARK = ['↑','→','↓','←']\n",
        "  POS_MY = [0,0]\n",
        "  POS_GOAL = [MAX_X, MAX_Y]\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super(Dist, self).__init__()\n",
        "    self.initState()\n",
        "    self.action_space = gym.spaces.Discrete(4)\n",
        "    self.observation_space = gym.spaces.Box(low=0, high=self.MAX_X * self.MAX_Y - 1, shape=(5,), dtype = np.uint8)\n",
        "\n",
        "  def reset(self):\n",
        "    # 状態を初期化します\n",
        "    self.initState()\n",
        "    return self.state()\n",
        "\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    # 座標移動\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    # ゴールまでの距離を計算\n",
        "    dist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    # ゴールしたか、枠外に出た場合は終了\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      reward = 1\n",
        "    return self.state(), reward, done, {}\n",
        "\n",
        "  # 現在の盤面の状態をコンソール表示\n",
        "  def render(self, mode='console', close=False):\n",
        "    print(str(self.state()))\n",
        "    for y in range(self.MAX_Y):\n",
        "      print('| ', end='')\n",
        "      for x in range(self.MAX_X):\n",
        "        print(self.renderMark(x, y), end='')\n",
        "      print(' |')\n",
        "\n",
        "  def renderMark(self, x, y):\n",
        "    if (x == self.POS_MY[0]) and (y == self.POS_MY[1]):\n",
        "      return 'P'\n",
        "    elif (x == self.POS_GOAL[0]) and (y == self.POS_GOAL[1]):\n",
        "      return 'G'\n",
        "    elif (x == self.PRE[0]) and (y == self.PRE[1]):\n",
        "      return self.ACTION_MARK[self.PRE[2]]\n",
        "    else:\n",
        "      return '.'\n",
        "  \n",
        "  # ゲームをリセットする(P/G の位置をランダムに配置)\n",
        "  def initState(self):\n",
        "    self.POS_MY = [random.randrange(self.MAX_X - 1), random.randrange(self.MAX_Y - 1)]\n",
        "    self.POS_GOAL = [random.randrange(self.MAX_X - 1), random.randrange(self.MAX_Y - 1)]\n",
        "    # ゴールまで近すぎる場合はやり直し\n",
        "    if self.distance(self.POS_MY, self.POS_GOAL) < 3:\n",
        "      self.initState()\n",
        "\n",
        "  # 枠外に出たかどうかを判定\n",
        "  def isOver(self):\n",
        "    if self.POS_MY[0] < 0 or self.POS_MY[1] < 0 or self.POS_MY[0] >= self.MAX_X or self.POS_MY[1] >= self.MAX_Y:\n",
        "      return True\n",
        "    return False \n",
        "\n",
        "  def state(self):\n",
        "    return [self.POS_MY[0], self.POS_MY[1], self.POS_GOAL[0], self.POS_GOAL[1], self.distance(self.POS_MY, self.POS_GOAL)]\n",
        "\n",
        "  # マンハッタン距離を返す\n",
        "  def distance(self, a, b):\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n1lXGpnyrST"
      },
      "source": [
        "### トレーニングしてみる\n",
        "\n",
        "上で作った環境クラスを使って、実際にトレーニングしてみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T8rmIJmVyrST",
        "outputId": "16253e50-2984-4af5-9ede-9d9259624672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training end\n"
          ]
        }
      ],
      "source": [
        "env0 = Dist()\n",
        "\n",
        "# モデルの生成\n",
        "#  verbose：ログの詳細表示(0:ログなし、1:訓練情報を表示、2:TensorFlowログを表示)\n",
        "model0 = PPO2('MlpPolicy', env0, verbose=0, tensorboard_log=\"../log/step0\")\n",
        "\n",
        "# モデルの学習回数\n",
        "sample = 10000\n",
        "model0.learn(total_timesteps=sample)\n",
        "# モデルをファイル保存\n",
        "model0.save('dist_model_' + str(sample))\n",
        "\n",
        "print('training end')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiphLZlyyrST"
      },
      "source": [
        "### 学習結果を確認してみましょう\n",
        "\n",
        "まずはグラフで学習結果を確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShMmQgnsyrST"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J28fC0sUyrSU"
      },
      "source": [
        "次に、作ったAIが想定通りに動くか実際に試してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GOgkaQ6yrSU"
      },
      "outputs": [],
      "source": [
        "# 状態をリセット\n",
        "env0.reset()\n",
        "i = 0\n",
        "while True:\n",
        "  i += 1\n",
        "  # 次のAIの行動を取得する\n",
        "  action, _ = model0.predict(env0.state())\n",
        "  state, reward, done, info = env0.step(action)\n",
        "  # 現在の状態を描画\n",
        "  env0.render()\n",
        "\n",
        "  if done:\n",
        "    print('end: ', i)\n",
        "    break\n",
        "  print('next action:', done, action, reward)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0vVcVCqyrSU"
      },
      "source": [
        "うまくゴールまで行けたでしょうか？\\\n",
        "次は、より最適な行動をAIが選択するように、どうやって改良するかを学びます。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AIのチューニング"
      ],
      "metadata": {
        "id": "-ywtOa9y3F6Y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2piOTKbyrSU"
      },
      "source": [
        "### 報酬とは？\n",
        "\n",
        "まずは環境クラスの step 関数をみてみます。\n",
        "\n",
        "```python\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    # 座標移動\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    # ゴールまでの距離を計算\n",
        "    dist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      reward = 1\n",
        "    return self.state(), reward, done, {}\n",
        "```\n",
        "\n",
        "action(次の行動) を与えて、現在の状態を更新し、reward(報酬) を返却しています。\n",
        "機械学習は、この報酬が大きくなる行動を選んでいます。\n",
        "\n",
        "上のコードでは、ゴールした時のみ報酬を与えていますが、この場合、どれだけ遠回りしてもゴールさえできれば報酬の合計は変わらないです。\\\n",
        "遠回りしないAIを作るには、ゴールに近づいたときに報酬を与えたり、遠回りした時に報酬を減らしたりしなければいけません。\n",
        "\n",
        "```python\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    beforeDist = self.distance()\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    dist = self.distance()\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      # ゴールした\n",
        "      reward = 1\n",
        "    elif dist > beforeDist:\n",
        "      # ゴールから遠ざかった\n",
        "      reward = -0.1\n",
        "    return self.state(), reward, done, {}\n",
        "```\n",
        "\n",
        "上のように変更して実行してみましょう。\\\n",
        "最短でゴールすれば、報酬は `1`、遠回りした回数が多いほど報酬が減らされることになります。\\\n",
        "tensorboard のグラフを確認して、どのような変化があったか確認してみましょう。\n",
        "\n",
        "今回の移動ゲームはルールが単純ですが、複雑になるほど報酬の与え方を調整しなければいけません。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szXEWQg4yrSV"
      },
      "source": [
        "### 学習回数とは？\n",
        "\n",
        "先ほどの例では、サンプル数を１万回でトレーニングしました。\n",
        "\n",
        "```python\n",
        "# モデルの学習回数\n",
        "sample = 10000\n",
        "model0.learn(total_timesteps=sample)\n",
        "model0.save('dist_model_' + str(sample))\n",
        "```\n",
        "\n",
        "こちらの数を変更して、もう一度実行してみてください。\n",
        "\n",
        "今回は単純なゲームなので、あまり変化が見られないかもしれませんが、基本的には学習回数を増やせばその分より良い行動をとるAIになります。\\\n",
        "しかし学習回数が多くなると、特定のパターン（攻略法）だけを学習してしまい、全体のパターンをつかめなくなる ”過学習” という現象が発生しやすくなります。\n",
        "\n",
        "学習の様子を tensorboard のグラフで確認したり、実際に動かしてみながら、最適な学習回数を探す必要があります。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e588ruV6yrSV"
      },
      "source": [
        "### その他の機械学習AIチューニング方法\n",
        "\n",
        "今回はトレーニングの際に、機械学習アルゴリズムとして、[\"PPO2\"](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html) というアルゴリズムと、[\"MlpPolicy\"](https://stable-baselines.readthedocs.io/en/master/modules/policies.html) を使っています。\n",
        "\n",
        "```python\n",
        "model0 = PPO2('MlpPolicy', env0, verbose=0, tensorboard_log=\"../log/step0\")\n",
        "```\n",
        "\n",
        "これらが具体的にどんなものかは、各自で調べてみてください。\n",
        "内容は非常に難しいですが、攻略がうまくいかない場合はアルゴリズムから変更してみるのもいいかもしれません。\n",
        "\n",
        "パラメータもデフォルト値を使いましたが、今回のゲームでは、例えば１回ごとの行動でゴールに近づいた場合に報酬を与えたり、離れた場合にマイナスの報酬を与えるようなstep関数を作ったとしましょう。\n",
        "その場合、シナリオ全体の報酬ではなく、1回の行動ごとに高い報酬を得るように行動するAIを作りたいです。\\\n",
        "そんな時には、割引率(gamma)を小さな値にしたり、学習率(lerning_rate)を小さくしたほうがよいかもしれません。\n",
        "\n",
        "```python\n",
        "model0 = PPO2('MlpPolicy', env0, gamma=0.6, lerning_rate=0.01, verbose=0, tensorboard_log=\"../log/step0_2\")\n",
        "```\n",
        "\n",
        "逆に、１回のゲーム全体でみてより大きい報酬を得たい場合は、それらの値を大きくすると、AIの行動が変わってきます。\\\n",
        "報酬の与え方次第では、遠回りしてゴールまでの移動回数を大きくしたほうが、シナリオごとの総報酬が大きくなってしまい、いつまでもゴールしないAIができてしまうかもしれません。\n",
        "\n",
        "アルゴリズムごとに他にもたくさんのパラメータがありますので、調べてみるとより強いAIができるかもしれません。\\\n",
        "パラメータを調整するのと合わせて、学習結果のグラフを読み取る力もつけていく必要があります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr2HxAneyrSV"
      },
      "source": [
        "### Challenge!\n",
        "\n",
        "ゲームの盤面に障害物（プレイヤーが移動できないマス）を置いた時、正しくゴールまで移動できるAIを作ってみましょう！\\\n",
        "難しい場合は [こちら](https://ailog.site/2021/05/23/2021/0523/) を参考にしてみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8xdTSHH4ldN"
      },
      "source": [
        "## コネクトフォーのAIを作る\n",
        "\n",
        "いよいよコネクトフォーのAIを作ってみましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg8OYVmusXFl"
      },
      "source": [
        "### game_util.py\n",
        "\n",
        "コネクトフォー独自のルールやロジックなど"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kRalBw_JrcXR",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import random\n",
        "\n",
        "class GameUtil:\n",
        "  @staticmethod\n",
        "  def stdinToState(stdin, blank='0', my='1', your='2'):\n",
        "    # サーバから受け取る盤面の情報を読み込む\n",
        "    ao = stdin.splitlines()\n",
        "    meta = ao.pop(0).split(' ')\n",
        "    return list(map(lambda x: list(re.sub('[^MB]', 'Y', x.replace('.', 'B').replace(meta[2], 'M')).replace('Y', your).replace('B', blank).replace('M', my)), ao))\n",
        "\n",
        "  def listToState(ao, meta, blank='0', my='1', your='2'):\n",
        "    # 一次元配列で受け取った盤面の情報を二次元配列に置き換える\n",
        "    for row in range(int(meta[1])):\n",
        "      for col in range(int(meta[0])):\n",
        "        if ao[row][col] == '.':\n",
        "          ao[row][col] = blank\n",
        "        elif ao[row][col] == meta[2]:\n",
        "          ao[row][col] = my\n",
        "        else:\n",
        "          ao[row][col] = your\n",
        "    return ao\n",
        "\n",
        "  @staticmethod\n",
        "  def resetState(row = 6, col = 7):\n",
        "    return [['0'] * col for i in range(row)]\n",
        "\n",
        "  @staticmethod\n",
        "  def fallCoin(state, action, mark='1', blank='0'):\n",
        "    \"\"\" Return new state\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): state list\n",
        "        action (number): [colmn number]\n",
        "        mark (str, optional): [description]. Defaults to '1'.\n",
        "        blank (str, optional): [description]. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        list: new state\n",
        "    \"\"\"\n",
        "    fallNg = True\n",
        "    for ry in range(len(state)):\n",
        "      y = len(state) - ry - 1\n",
        "      if state[y][action] == blank:\n",
        "        state[y][action] = mark\n",
        "        fallNg = False\n",
        "        break\n",
        "    return state, fallNg\n",
        "\n",
        "  @staticmethod\n",
        "  def checkEnd(state, goal=4, blank='0'):\n",
        "    \"\"\" Check if the game is finished\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): game state list\n",
        "        goal (int, optional): goal count. Defaults to 4.\n",
        "        blank (str, optional): blank mark. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        str: Win mark or blank\n",
        "    \"\"\"\n",
        "    # GameUtil.render(state)\n",
        "    # check row(-)\n",
        "    for row in range(len(state)):\n",
        "      for col in range(len(state[row]) - goal + 1):\n",
        "        tmpMark = state[row][col]\n",
        "        if tmpMark == blank:\n",
        "          continue\n",
        "        for p in range(goal - 1):\n",
        "          if tmpMark != state[row][col + p + 1]:\n",
        "            tmpMark = blank\n",
        "            break\n",
        "        \n",
        "        if tmpMark != blank:\n",
        "          return tmpMark\n",
        "\n",
        "    # check col(|)\n",
        "    for col in range(len(state[0])):\n",
        "      for row in range(len(state) - goal + 1):\n",
        "        tmpMark = state[row][col]\n",
        "        if tmpMark == blank:\n",
        "          continue\n",
        "        for p in range(goal - 1):\n",
        "          if tmpMark != state[row + p + 1][col]:\n",
        "            tmpMark = blank\n",
        "            break\n",
        "\n",
        "        if tmpMark != blank:\n",
        "          return tmpMark\n",
        "\n",
        "    # check /\n",
        "    for row in range(goal - 1, len(state)):\n",
        "      for col in range(0, len(state[row]) - goal + 1):\n",
        "        tmp = state[row][col]\n",
        "        if tmp == blank:\n",
        "          continue\n",
        "        for r in range(1, goal):\n",
        "          if tmp != state[row - r][col + r]:\n",
        "            tmp = blank\n",
        "            break\n",
        "        if tmp != blank:\n",
        "          return tmp\n",
        "\n",
        "    # check \\\n",
        "    for row in range(len(state) - goal + 1):\n",
        "      for col in range(len(state[row]) - goal + 1):\n",
        "        tmp = state[row][col]\n",
        "        if tmp == blank:\n",
        "          continue\n",
        "        for r in range(1, goal):\n",
        "          if tmp != state[row + r][col + r]:\n",
        "            tmp = blank\n",
        "            break\n",
        "        if tmp != blank:\n",
        "          return tmp\n",
        "\n",
        "    return blank\n",
        "\n",
        "  @staticmethod\n",
        "  def checkReach(state, mark = '1', goal=4, blank='0'):\n",
        "    \"\"\" Check if the game is Reach\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): game state list\n",
        "        goal (int, optional): goal count. Defaults to 4.\n",
        "        blank (str, optional): blank mark. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        str: Win mark or blank\n",
        "        pos: reach column\n",
        "    \"\"\"\n",
        "    ret = []\n",
        "    for i in range(len(state[0])):\n",
        "      ps, _ = GameUtil.fallCoin(GameUtil.stateCopy(state), i, mark, blank)\n",
        "      ec = GameUtil.checkEnd(ps, goal, blank)\n",
        "      if ec != blank:\n",
        "        ret.append([ec, i])\n",
        "    return ret\n",
        "\n",
        "  @staticmethod\n",
        "  def stateCopy(state):\n",
        "    row = len(state)\n",
        "    col = len(state[0])\n",
        "    ret = [['0'] * col for i in range(row)]\n",
        "    for r in range(row):\n",
        "      for c in range(col):\n",
        "        ret[r][c] = state[r][c]\n",
        "    return ret\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def render(state, my = '1', blank = '0'):\n",
        "    print('-0-1-2-3-4-5-6-')\n",
        "    for i in range(len(state)):\n",
        "      print(' ', end='')\n",
        "      for j in range(len(state[i])):\n",
        "        mark = '☆'\n",
        "        if state[i][j] == my:\n",
        "          mark = '◆'\n",
        "        elif state[i][j] == blank:\n",
        "          mark = '・'\n",
        "        print(mark, end='')\n",
        "      print()\n",
        "    print('--------------')\n",
        "\n",
        "  @staticmethod\n",
        "  def enemyPlay(state):\n",
        "    # todo\n",
        "    pos = random.randrange(7)\n",
        "    if state[0][pos] == '0':\n",
        "      return pos\n",
        "    else:\n",
        "      return GameUtil.enemyPlay(state)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYwEWmYjshwY"
      },
      "source": [
        "### environment.py\n",
        "\n",
        "StableBaselines の環境クラス"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "za-bTKj-sjpY",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "class Con4(gym.Env):\n",
        "  MY_MARK = '1'\n",
        "  BLANK_MARK = '0'\n",
        "  MAX_ROW = 6\n",
        "  MAX_COL = 7\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Con4, self).__init__()\n",
        "    self.board = GameUtil.resetState(self.MAX_ROW, self.MAX_COL)\n",
        "    self.action_space = gym.spaces.Discrete(self.MAX_COL)\n",
        "    self.observation_space = gym.spaces.Box(low=0, high=2, shape=(self.MAX_ROW, self.MAX_COL))\n",
        "\n",
        "  def reset(self):\n",
        "    # 状態を初期化します\n",
        "    self.board = GameUtil.resetState(self.MAX_ROW, self.MAX_COL)\n",
        "    return self.board\n",
        "\n",
        "  def step(self, action):\n",
        "    reward = 0\n",
        "    done = False\n",
        "    # アクション実行後の状態を取得する\n",
        "    self.board, stepNg = GameUtil.fallCoin(self.board, action, self.MY_MARK, self.BLANK_MARK)\n",
        "    if stepNg:\n",
        "      # この列にコインをこれ以上落とせなかった\n",
        "      done = True\n",
        "      reward = -10000\n",
        "      return self.board, reward, done, {}\n",
        "    # 相手の行動を追加する\n",
        "    self.board, stepNg = GameUtil.fallCoin(self.board, GameUtil.enemyPlay(self.board), '2', self.BLANK_MARK)\n",
        "    # ゲームが終了したかどうかを確認する\n",
        "    win = GameUtil.checkEnd(self.board)\n",
        "    if win == self.MY_MARK:\n",
        "      # 自分が勝った\n",
        "      done = True\n",
        "      reward = 1.0\n",
        "    elif win != self.BLANK_MARK:\n",
        "      # 相手が勝った\n",
        "      done = True\n",
        "      reward = -1\n",
        "    return self.board, reward, done, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    GameUtil.render(self.board, self.MY_MARK, self.BLANK_MARK)\n",
        "\n",
        "  def initState(self):\n",
        "    \"\"\" 盤面を初期化する\n",
        "\n",
        "    Returns:\n",
        "        list: 初期化された盤面の2次元配列\n",
        "    \"\"\"\n",
        "    return [[self.BLANK_MARK] * self.MAX_COL for i in range(self.MAX_ROW)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6cNp-NMsuBv"
      },
      "source": [
        "### training\n",
        "\n",
        "指定回数反復学習し、結果をモデルファイルとして保存する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2QmWXnhXsvJD",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "#!python3.7\n",
        "env = Con4()\n",
        "\n",
        "# モデルの生成\n",
        "#  verbose：ログの詳細表示(0:ログなし、1:訓練情報を表示、2:TensorFlowログを表示)\n",
        "model = PPO2('MlpPolicy', env, verbose=0, tensorboard_log='./log/con4')\n",
        "# model = PPO2(MlpPolicy, env, verbose=0)\n",
        "# モデルの学習\n",
        "sample = 20000\n",
        "model.learn(total_timesteps=sample)\n",
        "# モデルの保存\n",
        "model.save('con4_model_' + str(sample))\n",
        "\n",
        "print('training end', sample)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRrZuqD0TIU"
      },
      "source": [
        "### 学習結果の確認\n",
        "\n",
        "Tensorboard を使用して、学習の様子を確認します。\\\n",
        "パラメータや報酬ロジックを変更した際には違いを確認し、より強いAIになるよう調整しましょう\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "volXgUE_0YCO",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./log/con4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DKN-J9wuQst"
      },
      "source": [
        "### AIのテスト\n",
        "\n",
        "作ったAIが想定通りに動くか、まずはコンソールで試してみましょう"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "akzVT9PyuTr_",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "state = GameUtil.resetState(6, 7)\n",
        "i = 0\n",
        "\n",
        "while True:\n",
        "  i += 1\n",
        "  action, _ = model.predict(state)\n",
        "  state, done = GameUtil.fallCoin(state, action)\n",
        "  if done:\n",
        "    print('failed fall: ', action)\n",
        "    GameUtil.render(state)\n",
        "    break\n",
        "  done = GameUtil.checkEnd(state)\n",
        "  if done != '0':\n",
        "    print('end: ', i)\n",
        "    break\n",
        "\n",
        "  GameUtil.render(state)\n",
        "  if done != '0':\n",
        "    print('win ai: ', i)\n",
        "    break\n",
        "  print('AI action:', done, action)\n",
        "  action = input('input action > ')\n",
        "  state, done = GameUtil.fallCoin(state, int(action), mark = '2')\n",
        "  if done:\n",
        "    print('failed fall: ', action)\n",
        "    GameUtil.render(state)\n",
        "    break\n",
        "  done = GameUtil.checkEnd(state)\n",
        "  if done != '0':\n",
        "    print('win player: ', i)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKTyeXdLpNl4"
      },
      "source": [
        "### WebSocket準備\n",
        "\n",
        "ゲーム画面と連携するため、WebSocketの準備をします\\\n",
        "このプログラムは変更しないでください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9LOHYYgD1C80",
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "!pip install websocket-client --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sGl8CYkNpbmB",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import websocket\n",
        "import json\n",
        "try:\n",
        "    import thread\n",
        "except ImportError:\n",
        "    import _thread as thread\n",
        "import time\n",
        "\n",
        "class Websocket_Client():\n",
        "    isLogin = False\n",
        "    userNo = -1\n",
        "\n",
        "    def __init__(self, host_addr):\n",
        "\n",
        "        # デバックログの表示/非表示設定\n",
        "        websocket.enableTrace(True)\n",
        "\n",
        "        # WebSocketAppクラスを生成\n",
        "        # 関数登録のために、ラムダ式を使用\n",
        "        self.ws = websocket.WebSocketApp(host_addr,\n",
        "            on_message = lambda ws, msg: self.on_message(ws, msg),\n",
        "            on_error   = lambda ws, msg: self.on_error(ws, msg),\n",
        "            on_close   = lambda ws: self.on_close(ws))\n",
        "        self.ws.on_open = lambda ws: self.on_open(ws)\n",
        "\n",
        "    # メッセージ受信に呼ばれる関数\n",
        "    def on_message(self, ws, message):\n",
        "        print(\"### receive : {}\".format(message))\n",
        "        sendData = {}\n",
        "        msg = json.loads(message)\n",
        "        if msg['call'] == 'reload':\n",
        "            print('+++++ reload')\n",
        "            if self.isLogin:\n",
        "                print('+++ Logedin reload')\n",
        "            elif 'player' in msg:\n",
        "                print('ゲームが進行中です。想定外の場合はゲーム画面からゲーム終了ボタンを押してください。')\n",
        "                self.ws.close()\n",
        "                return\n",
        "            elif 'user0' in msg:\n",
        "                print('先攻のユーザがログイン中です。後攻で参加します。')\n",
        "                sendData['user1'] = input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "                self.userNo = '1'\n",
        "            elif 'user1' in msg:\n",
        "                print('後攻のユーザがログイン中です。先攻で参加します。')\n",
        "                sendData['user0'] = input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "                self.userNo = '0'\n",
        "            else:\n",
        "                self.userNo = input('先攻で参加する場合は0, 後攻で参加する場合は1を入力 > ')\n",
        "                sendData['user'+self.userNo] = input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "        elif msg['call'] == 'step':\n",
        "            print('+++++ step')\n",
        "            state = GameUtil.stdinToState(msg['stdin'])\n",
        "            GameUtil.render(state)\n",
        "            if self.isLogin == False:\n",
        "                print('ゲームが進行中です。想定外の場合はゲーム画面からゲーム終了ボタンを押してください。')\n",
        "                self.ws.close()\n",
        "                return\n",
        "            if self.userNo == str(msg['player']):\n",
        "                print('action start')\n",
        "                sendData['call'] = 'step'\n",
        "                sendData['stdin'] = msg['stdin']\n",
        "                sendData['player'] = self.userNo\n",
        "                # 手動で入力する場合\n",
        "                # sendData['stdout'] = input('next action >')\n",
        "                action, _ = model.predict(state)\n",
        "                sendData['stdout'] = int(action)\n",
        "            else:\n",
        "                print('skip action')\n",
        "                return\n",
        "        elif msg['call'] == 'login':\n",
        "            print('+++++ login')\n",
        "            return\n",
        "        elif msg['call'] == 'end':\n",
        "            print('+++++ end', msg['message'])\n",
        "            GameUtil.render(GameUtil.stdinToState(msg['stdin']))\n",
        "            self.ws.close()\n",
        "            return\n",
        "        else:\n",
        "            print('+++++ unknown call', msg['call'])\n",
        "            return\n",
        "\n",
        "        if 'call' in sendData:\n",
        "            self.sendJson(sendData)\n",
        "            \n",
        "\n",
        "    # エラー時に呼ばれる関数\n",
        "    def on_error(self, ws, error):\n",
        "        print(error)\n",
        "\n",
        "    # サーバーから切断時に呼ばれる関数\n",
        "    def on_close(self, ws):\n",
        "        print(\"### closed ###\")\n",
        "\n",
        "    # サーバーから接続時に呼ばれる関数\n",
        "    def on_open(self, ws):\n",
        "        thread.start_new_thread(self.run, ())\n",
        "        print('+++ start new thread end');\n",
        "        time.sleep(1)\n",
        "        self.sendJson({'call': 'reload'})\n",
        "\n",
        "    # サーバーから接続時にスレッドで起動する関数\n",
        "    def run(self, *args):\n",
        "        while True:\n",
        "            time.sleep(0.1)\n",
        "            # input_data = input(\"send data:\") \n",
        "            # self.ws.send(input_data)\n",
        "    \n",
        "        self.ws.close()\n",
        "        print(\"thread terminating...\")\n",
        "    def sendJson(self, data):\n",
        "        print('### send:', data)\n",
        "        self.ws.send(json.dumps(data))\n",
        "\n",
        "    # websocketクライアント起動\n",
        "    def run_forever(self):\n",
        "        self.ws.run_forever()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDO2gdUYqB3v"
      },
      "source": [
        "### プレイ\n",
        "\n",
        "[ゲーム画面](https://www.tomiko.cf/red/con4/room/demo-a.html) を開いて、作ったAIと対戦してみよう！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_VTXLRZU4LTi",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "HOST_ADDR = \"wss://www.tomiko.cf/red/api/con4/demo-a\"\n",
        "ws_client = Websocket_Client(HOST_ADDR)\n",
        "ws_client.run_forever()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "P36BCWmvyrSY"
      },
      "source": [
        "### より強いAIを作るには\n",
        "\n",
        "移動ゲームと違って、コネクトフォーのAIでは考えることがたくさんあります。\n",
        "\n",
        "* 報酬は？\n",
        "\n",
        "上のサンプルでは、勝った場合・負けた場合のみ報酬を与えましたが、最終結果だけを見るのではなく、例えばリーチになった場合や、相手のリーチを阻止した・見逃した場合など、いろいろなパターンで報酬を与えるべきです。\\\n",
        "どのパターンでどれだけの報酬を与えるのがいいか、いろいろ試してみましょう。\n",
        "\n",
        "* 学習回数は？\n",
        "\n",
        "手っ取り早く強いAIにするために、学習回数を多くしたいところですが、例えば100万回、1000万回で試してみると、過学習というものが具体的にどんな現象かわかりやすいと思います。\\\n",
        "(Google Colabで動かない場合は、ローカルPCなどで試してみましょう) \\\n",
        "対戦形式のAIでは、過学習による悪影響がわかりやすく出やすいので、どうすればそれを防げるか（学習パターンの改善）考えてみましょう\n",
        "\n",
        "* アルゴリズムやパラメータは？\n",
        "\n",
        "移動ゲームの説明であったように、報酬の計算方法に合わせてパラメータを変更してみましょう。\\\n",
        "また、今回使用した PPO2 / MlpPolicy は汎用性が高いので、とりあえずで使うのにはちょうどいいですが、複雑なパターンのばあいはACKTR を使ってみたり\\\n",
        "あるいは機械学習ではなく [模倣学習(GAIL)](https://note.com/npaka/n/n2289ad7f4a3e) を使ってみるのも面白いかもしれません。\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "A-1Be_bkrYOi"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit (system)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "ecf089708d010a6d266613a2c577b66c9875854ea8788c7d19d60d14e80f5462"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}