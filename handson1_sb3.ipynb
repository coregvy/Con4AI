{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCv7l4hvQKWNoa4jqbAgp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coregvy/Con4AI/blob/master/handson1_sb3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# コネクトフォー の ゲームAIを作ろう(SB3)\n",
        "\n",
        "Stable Baselines3 を使用したハンズオンです。\n"
      ],
      "metadata": {
        "id": "kvz16pC922yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies and Stable Baselines3 Using Pip\n"
      ],
      "metadata": {
        "id": "hN1oNpuo5EeA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkQ2h8tp2inB"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y -q ffmpeg freeglut3-dev xvfb  # For visualization\n",
        "!pip install stable-baselines3[extra] --quiet\n",
        "!pip install pyglet==1.4 --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "EGDOMQfr21uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.ppo.policies import MlpPolicy\n",
        "import random\n",
        "import re\n"
      ],
      "metadata": {
        "id": "qabaeQuc5hFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 簡単なゲームでAIを学ぶ\n",
        "\n",
        "上下左右に移動して、ゴールを目指すゲームという簡単なルールのゲームを通して、[StableBaselines](https://stable-baselines.readthedocs.io/en/master/index.html) / [OpenAI Gym](https://github.com/openai/gym) を使ったゲームAIの作り方を学んでいきます。\n",
        "\n",
        "### ゲームルール\n",
        "\n",
        "以下のような入力を与えます\n",
        "```\n",
        ".......\n",
        ".......\n",
        "..P....\n",
        ".......\n",
        ".......\n",
        ".....G.\n",
        ".......\n",
        "```\n",
        "7x7マスに `P` (Player) の位置から `G` (Goal) に向けて移動するゲームです。\n",
        "出力には\n",
        "\n",
        "- 0: 上\n",
        "- 1: 右\n",
        "- 2: 下\n",
        "- 3: 左\n",
        "\n",
        "に移動します。枠外に出てしまった場合は失敗です。\n"
      ],
      "metadata": {
        "id": "OzfFtsvm5-kV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 環境クラス\n",
        "\n",
        "ゲームのルールにあわせた、環境クラスを作成します。\\\n",
        "環境クラスでは以下のメソッドを定義する必要があります。\n",
        "* reset：状態を初期化します\n",
        "* step：次の行動を入力として、一つステップを進める関数を作成します。報酬の計算も行います。\n",
        "* render：現在の状態を描画します。中身は適当で大丈夫です\n",
        "\n",
        "また、以下の変数をコンストラクタで定義する必要があります。\n",
        "* action_space：実際の行動の数を設定\n",
        "* self.observation_space：状態空間の定義\n"
      ],
      "metadata": {
        "id": "aSukfdXcsk7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dist(gym.Env):\n",
        "  MAX_X = 7\n",
        "  MAX_Y = 7\n",
        "  ACTION_TOP = 0\n",
        "  ACTION_RIGHT = 1\n",
        "  ACTION_BOTTOM = 2\n",
        "  ACTION_LEFT = 3\n",
        "  PRE = [0,0,0]\n",
        "  ACTION_MARK = ['↑','→','↓','←']\n",
        "  POS_MY = [0,0]\n",
        "  POS_GOAL = [MAX_X, MAX_Y]\n",
        "\n",
        "  def __init__(self) -> None:\n",
        "    super(Dist, self).__init__()\n",
        "    self.initState()\n",
        "    self.action_space = gym.spaces.Discrete(4)\n",
        "    self.observation_space = gym.spaces.Box(low=0, high=self.MAX_X * self.MAX_Y - 1, shape=(5,), dtype = np.uint8)\n",
        "\n",
        "  def reset(self):\n",
        "    # 状態を初期化します\n",
        "    self.initState()\n",
        "    return self.state()\n",
        "\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    # 座標移動\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    # ゴールまでの距離を計算\n",
        "    dist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    # ゴールしたか、枠外に出た場合は終了\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      reward = 1\n",
        "    return self.state(), reward, done, {}\n",
        "\n",
        "  # 現在の盤面の状態をコンソール表示\n",
        "  def render(self, mode='console', close=False):\n",
        "    print(str(self.state()))\n",
        "    for y in range(self.MAX_Y):\n",
        "      print('| ', end='')\n",
        "      for x in range(self.MAX_X):\n",
        "        print(self.renderMark(x, y), end='')\n",
        "      print(' |')\n",
        "\n",
        "  def renderMark(self, x, y):\n",
        "    if (x == self.POS_MY[0]) and (y == self.POS_MY[1]):\n",
        "      return 'P'\n",
        "    elif (x == self.POS_GOAL[0]) and (y == self.POS_GOAL[1]):\n",
        "      return 'G'\n",
        "    elif (x == self.PRE[0]) and (y == self.PRE[1]):\n",
        "      return self.ACTION_MARK[self.PRE[2]]\n",
        "    else:\n",
        "      return '.'\n",
        "  \n",
        "  # ゲームをリセットする(P/G の位置をランダムに配置)\n",
        "  def initState(self):\n",
        "    self.POS_MY = [random.randrange(self.MAX_X - 1), random.randrange(self.MAX_Y - 1)]\n",
        "    self.POS_GOAL = [random.randrange(self.MAX_X - 1), random.randrange(self.MAX_Y - 1)]\n",
        "    # ゴールまで近すぎる場合はやり直し\n",
        "    if self.distance(self.POS_MY, self.POS_GOAL) < 3:\n",
        "      self.initState()\n",
        "\n",
        "  # 枠外に出たかどうかを判定\n",
        "  def isOver(self):\n",
        "    if self.POS_MY[0] < 0 or self.POS_MY[1] < 0 or self.POS_MY[0] >= self.MAX_X or self.POS_MY[1] >= self.MAX_Y:\n",
        "      return True\n",
        "    return False \n",
        "\n",
        "  def state(self):\n",
        "    return [self.POS_MY[0], self.POS_MY[1], self.POS_GOAL[0], self.POS_GOAL[1], self.distance(self.POS_MY, self.POS_GOAL)]\n",
        "\n",
        "  # マンハッタン距離を返す\n",
        "  def distance(self, a, b):\n",
        "    return abs(a[0] - b[0]) + abs(a[1] - b[1])\n"
      ],
      "metadata": {
        "id": "Qvune7ZU5_Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### トレーニングしてみる\n",
        "\n",
        "上で作った環境クラスを使って、実際にトレーニングしてみます。"
      ],
      "metadata": {
        "id": "pnxyG0tz6ERT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env0 = Dist()\n",
        "\n",
        "# モデルの生成\n",
        "#  verbose：ログの詳細表示(0:ログなし、1:訓練情報を表示、2:TensorFlowログを表示)\n",
        "model0 = PPO(MlpPolicy, env0, verbose=0, tensorboard_log=\"./log/step0\")\n",
        "\n",
        "# モデルの学習回数\n",
        "sample = 10000\n",
        "model0.learn(total_timesteps=sample, tb_log_name=\"first_run\")\n",
        "# モデルをファイル保存\n",
        "model0.save('dist_model_' + str(sample))\n",
        "\n",
        "print('training end')\n"
      ],
      "metadata": {
        "id": "i5d7fADn6Ewq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習結果を確認してみましょう\n",
        "\n",
        "まずはグラフで学習結果を確認してみましょう。"
      ],
      "metadata": {
        "id": "_BybsuAp6yxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./log/"
      ],
      "metadata": {
        "id": "hgsl2d1I6zP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に、作ったAIが想定通りに動くか実際に試してみましょう"
      ],
      "metadata": {
        "id": "zjpFq5LD9hz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 状態をリセット\n",
        "env0.reset()\n",
        "i = 0\n",
        "while True:\n",
        "  i += 1\n",
        "  # 次のAIの行動を取得する\n",
        "  action, _ = model0.predict(env0.state())\n",
        "  state, reward, done, info = env0.step(action)\n",
        "  # 現在の状態を描画\n",
        "  env0.render()\n",
        "\n",
        "  if done:\n",
        "    print('end: ', i)\n",
        "    break\n",
        "  print('next action:', done, action, reward)\n"
      ],
      "metadata": {
        "id": "jyPur5lt9j6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "うまくゴールまで行けたでしょうか？\\\n",
        "次は、より最適な行動をAIが選択するように、どうやって改良するかを学びます。"
      ],
      "metadata": {
        "id": "Coyd9L309xr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hHl64rfss_AX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AIのチューニング"
      ],
      "metadata": {
        "id": "BR61tkAX9yH7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 報酬とは？\n",
        "\n",
        "機械学習では、教師データ（入力とそれに対する正しい答え）の代わりに、入力に対する報酬を評価するロジックを作成します。\n",
        "\n",
        "![image.png](https://github.com/coregvy/Con4AI/raw/master/reward.png)\n",
        "\n",
        "環境クラスの step 関数をみてみます。\n",
        "\n",
        "```python\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    # 座標移動\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    # ゴールまでの距離を計算\n",
        "    dist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      reward = 1\n",
        "    return self.state(), reward, done, {}\n",
        "```\n",
        "\n",
        "action(次の行動) を与えて、現在の状態を更新し、reward(報酬) を返却しています。\n",
        "機械学習は、この報酬が大きくなる行動を選んでいます。\n",
        "\n",
        "上のコードでは、ゴールした時のみ報酬を与えていますが、この場合、どれだけ遠回りしてもゴールさえできれば報酬の合計は変わらないです。\\\n",
        "遠回りしないAIを作るには、ゴールに近づいたときに報酬を与えたり、遠回りした時に報酬を減らしたりしなければいけません。\n",
        "\n",
        "```python\n",
        "  def step(self, action):\n",
        "    self.PRE = [self.POS_MY[0], self.POS_MY[1], action]\n",
        "    beforeDist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    if action == self.ACTION_TOP:\n",
        "      self.POS_MY[1] -= 1\n",
        "    elif action == self.ACTION_RIGHT:\n",
        "      self.POS_MY[0] += 1\n",
        "    elif action == self.ACTION_BOTTOM:\n",
        "      self.POS_MY[1] += 1\n",
        "    elif action == self.ACTION_LEFT:\n",
        "      self.POS_MY[0] -= 1\n",
        "    \n",
        "    dist = self.distance(self.POS_MY, self.POS_GOAL)\n",
        "    done = (dist == 0) or self.isOver()\n",
        "    reward = 0\n",
        "    if dist == 0:\n",
        "      # ゴールした\n",
        "      reward = 1\n",
        "    elif dist > beforeDist:\n",
        "      # ゴールから遠ざかった\n",
        "      reward = -0.1\n",
        "    return self.state(), reward, done, {}\n",
        "```\n",
        "\n",
        "上のように変更して実行してみましょう。\\\n",
        "最短でゴールすれば、報酬は `1`、遠回りした回数が多いほど報酬が減らされることになります。\\\n",
        "tensorboard のグラフを確認して、どのような変化があったか確認してみましょう。\n",
        "\n",
        "今回の移動ゲームはルールが単純ですが、複雑になるほど報酬の与え方を調整しなければいけません。\n"
      ],
      "metadata": {
        "id": "N_G_t8fn9ymz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習回数とは？\n",
        "\n",
        "先ほどの例では、サンプル数を１万回でトレーニングしました。\n",
        "\n",
        "```python\n",
        "# モデルの学習回数\n",
        "sample = 10000\n",
        "model0.learn(total_timesteps=sample)\n",
        "model0.save('dist_model_' + str(sample))\n",
        "```\n",
        "\n",
        "こちらの数を変更して、もう一度実行してみてください。\n",
        "\n",
        "今回は単純なゲームなので、あまり変化が見られないかもしれませんが、基本的には学習回数を増やせばその分より良い行動をとるAIになります。\\\n",
        "しかし学習回数が多くなると、特定のパターン（攻略法）だけを学習してしまい、全体のパターンをつかめなくなる ”過学習” という現象が発生しやすくなります。\n",
        "\n",
        "学習の様子を tensorboard のグラフで確認したり、実際に動かしてみながら、最適な学習回数を探す必要があります。\n",
        "\n"
      ],
      "metadata": {
        "id": "c7FLBWEvtD5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### その他の機械学習AIチューニング方法\n",
        "\n",
        "今回はトレーニングの際に、機械学習アルゴリズムとして、[\"PPO2\"](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html) というアルゴリズムと、[\"MlpPolicy\"](https://stable-baselines.readthedocs.io/en/master/modules/policies.html) を使っています。\n",
        "\n",
        "```python\n",
        "model0 = PPO(MlpPolicy, env0, verbose=0, tensorboard_log=\"../log/step0\")\n",
        "```\n",
        "\n",
        "これらが具体的にどんなものかは、各自で調べてみてください。\n",
        "内容は非常に難しいですが、攻略がうまくいかない場合はアルゴリズムから変更してみるのもいいかもしれません。\n",
        "\n",
        "パラメータもデフォルト値を使いましたが、今回のゲームでは、例えば１回ごとの行動でゴールに近づいた場合に報酬を与えたり、離れた場合にマイナスの報酬を与えるようなstep関数を作ったとしましょう。\n",
        "その場合、シナリオ全体の報酬ではなく、1回の行動ごとに高い報酬を得るように行動するAIを作りたいです。\\\n",
        "そんな時には、割引率(gamma)を小さな値にしたり、学習率(lerning_rate)を小さくしたほうがよいかもしれません。\n",
        "\n",
        "```python\n",
        "model0 = PPO(MlpPolicy, env0, gamma=0.6, lerning_rate=0.01, verbose=0, tensorboard_log=\"../log/step0_2\")\n",
        "```\n",
        "\n",
        "逆に、１回のゲーム全体でみてより大きい報酬を得たい場合は、それらの値を大きくすると、AIの行動が変わってきます。\\\n",
        "報酬の与え方次第では、遠回りしてゴールまでの移動回数を大きくしたほうが、シナリオごとの総報酬が大きくなってしまい、いつまでもゴールしないAIができてしまうかもしれません。\n",
        "\n",
        "アルゴリズムごとに他にもたくさんのパラメータがありますので、調べてみるとより強いAIができるかもしれません。\\\n",
        "パラメータを調整するのと合わせて、学習結果のグラフを読み取る力もつけていく必要があります。\n"
      ],
      "metadata": {
        "id": "090Wd7VrtHYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Challenge!\n",
        "\n",
        "ゲームの盤面に障害物（プレイヤーが移動できないマス）を置いた時、正しくゴールまで移動できるAIを作ってみましょう！\\\n",
        "難しい場合は [こちら](https://ailog.site/2021/05/23/2021/0523/) を参考にしてみましょう。"
      ],
      "metadata": {
        "id": "UtdZEQ5ktNAf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## コネクトフォーのAIを作る\n",
        "\n",
        "いよいよコネクトフォーのAIを作ってみましょう。"
      ],
      "metadata": {
        "id": "fhry-i9rtRg7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### game_util.py\n",
        "\n",
        "コネクトフォー独自のルールやロジックなど"
      ],
      "metadata": {
        "id": "nCrPK75392dz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GameUtil:\n",
        "  @staticmethod\n",
        "  def stdinToState(stdin, blank='0', my='1', your='2'):\n",
        "    # サーバから受け取る盤面の情報を読み込む\n",
        "    ao = stdin.splitlines()\n",
        "    meta = ao.pop(0).split(' ')\n",
        "    # return list(map(lambda x: list(re.sub('[^MB]', 'Y', x.replace('.', 'B').replace(meta[2], 'M').replace('Y', your).replace('B', blank).replace('M', my))), ao))\n",
        "    return GameUtil.listToState(ao, meta)\n",
        "\n",
        "  def listToState(ao, meta, blank=0, my=1, your=2):\n",
        "    # 一次元配列で受け取った盤面の情報を二次元配列に置き換える\n",
        "    ao2 = GameUtil.resetState()\n",
        "    for row in range(int(meta[1])):\n",
        "      for col in range(int(meta[0])):\n",
        "        if ao[row][col] == '.':\n",
        "          ao2[row][col] = blank\n",
        "        elif ao[row][col] == meta[2]:\n",
        "          ao2[row][col] = my\n",
        "        else:\n",
        "          ao2[row][col] = your\n",
        "    return ao2\n",
        "\n",
        "  @staticmethod\n",
        "  def resetState(row = 6, col = 7):\n",
        "    return [[0] * col for i in range(row)]\n",
        "\n",
        "  @staticmethod\n",
        "  def fallCoin(state, action, mark=1, blank=0):\n",
        "    \"\"\" Return new state\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): state list\n",
        "        action (number): [colmn number]\n",
        "        mark (str, optional): [description]. Defaults to '1'.\n",
        "        blank (str, optional): [description]. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        list: new state\n",
        "    \"\"\"\n",
        "    fallNg = True\n",
        "    for ry in range(len(state)):\n",
        "      y = len(state) - ry - 1\n",
        "      if state[y][action] == blank:\n",
        "        state[y][action] = mark\n",
        "        fallNg = False\n",
        "        break\n",
        "    return state, fallNg\n",
        "\n",
        "  @staticmethod\n",
        "  def checkEnd(state, goal=4, blank=0):\n",
        "    \"\"\" Check if the game is finished\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): game state list\n",
        "        goal (int, optional): goal count. Defaults to 4.\n",
        "        blank (str, optional): blank mark. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        str: Win mark or blank\n",
        "    \"\"\"\n",
        "    # GameUtil.render(state)\n",
        "    # check row(-)\n",
        "    for row in range(len(state)):\n",
        "      for col in range(len(state[row]) - goal + 1):\n",
        "        tmpMark = state[row][col]\n",
        "        if tmpMark == blank:\n",
        "          continue\n",
        "        for p in range(goal - 1):\n",
        "          if tmpMark != state[row][col + p + 1]:\n",
        "            tmpMark = blank\n",
        "            break\n",
        "        \n",
        "        if tmpMark != blank:\n",
        "          return tmpMark\n",
        "\n",
        "    # check col(|)\n",
        "    for col in range(len(state[0])):\n",
        "      for row in range(len(state) - goal + 1):\n",
        "        tmpMark = state[row][col]\n",
        "        if tmpMark == blank:\n",
        "          continue\n",
        "        for p in range(goal - 1):\n",
        "          if tmpMark != state[row + p + 1][col]:\n",
        "            tmpMark = blank\n",
        "            break\n",
        "\n",
        "        if tmpMark != blank:\n",
        "          return tmpMark\n",
        "\n",
        "    # check /\n",
        "    for row in range(goal - 1, len(state)):\n",
        "      for col in range(0, len(state[row]) - goal + 1):\n",
        "        tmp = state[row][col]\n",
        "        if tmp == blank:\n",
        "          continue\n",
        "        for r in range(1, goal):\n",
        "          if tmp != state[row - r][col + r]:\n",
        "            tmp = blank\n",
        "            break\n",
        "        if tmp != blank:\n",
        "          return tmp\n",
        "\n",
        "    # check \\\n",
        "    for row in range(len(state) - goal + 1):\n",
        "      for col in range(len(state[row]) - goal + 1):\n",
        "        tmp = state[row][col]\n",
        "        if tmp == blank:\n",
        "          continue\n",
        "        for r in range(1, goal):\n",
        "          if tmp != state[row + r][col + r]:\n",
        "            tmp = blank\n",
        "            break\n",
        "        if tmp != blank:\n",
        "          return tmp\n",
        "\n",
        "    return blank\n",
        "\n",
        "  @staticmethod\n",
        "  def checkReach(state, mark = 1, goal=4, blank=0):\n",
        "    \"\"\" Check if the game is Reach\n",
        "\n",
        "    Args:\n",
        "        state (list[list[str]]): game state list\n",
        "        goal (int, optional): goal count. Defaults to 4.\n",
        "        blank (str, optional): blank mark. Defaults to '0'.\n",
        "\n",
        "    Returns:\n",
        "        str: Win mark or blank\n",
        "        pos: reach column\n",
        "    \"\"\"\n",
        "    ret = []\n",
        "    for i in range(len(state[0])):\n",
        "      ps, _ = GameUtil.fallCoin(GameUtil.stateCopy(state), i, mark, blank)\n",
        "      ec = GameUtil.checkEnd(ps, goal, blank)\n",
        "      if ec != blank:\n",
        "        ret.append([ec, i])\n",
        "    return ret\n",
        "\n",
        "  @staticmethod\n",
        "  def stateCopy(state):\n",
        "    row = len(state)\n",
        "    col = len(state[0])\n",
        "    ret = [[0] * col for i in range(row)]\n",
        "    for r in range(row):\n",
        "      for c in range(col):\n",
        "        ret[r][c] = state[r][c]\n",
        "    return ret\n",
        "\n",
        "\n",
        "  @staticmethod\n",
        "  def render(state, my = 1, blank = 0):\n",
        "    print('-0-1-2-3-4-5-6-')\n",
        "    for i in range(len(state)):\n",
        "      print(' ', end='')\n",
        "      for j in range(len(state[i])):\n",
        "        mark = '☆'\n",
        "        if state[i][j] == my:\n",
        "          mark = '◆'\n",
        "        elif state[i][j] == blank:\n",
        "          mark = '・'\n",
        "        print(mark, end='')\n",
        "      print()\n",
        "    print('--------------')\n",
        "\n",
        "  @staticmethod\n",
        "  def enemyPlay(state):\n",
        "    # todo\n",
        "    pos = random.randrange(7)\n",
        "    if state[0][pos] == 0:\n",
        "      return pos\n",
        "    else:\n",
        "      return GameUtil.enemyPlay(state)\n"
      ],
      "metadata": {
        "id": "DbSBxMxH926Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test\n",
        "state = GameUtil.resetState(6, 7)\n",
        "GameUtil.render(state)\n",
        "GameUtil.fallCoin(state, 2)\n",
        "GameUtil.render(state)\n",
        "done = GameUtil.checkEnd(state)\n",
        "print('check: ', done)\n"
      ],
      "metadata": {
        "id": "z3Ys5DjyAIYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### environment.py\n",
        "\n",
        "StableBaselines の環境クラス"
      ],
      "metadata": {
        "id": "BTrIqD_EAYCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Con4(gym.Env):\n",
        "  MY_MARK = 1\n",
        "  BLANK_MARK = 0\n",
        "  MAX_ROW = 6\n",
        "  MAX_COL = 7\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Con4, self).__init__()\n",
        "    self.board = GameUtil.resetState(self.MAX_ROW, self.MAX_COL)\n",
        "    self.action_space = gym.spaces.Discrete(self.MAX_COL)\n",
        "    self.observation_space = gym.spaces.Box(low=0, high=2, shape=(self.MAX_ROW, self.MAX_COL))\n",
        "\n",
        "  def reset(self):\n",
        "    # 状態を初期化します\n",
        "    self.board = GameUtil.resetState(self.MAX_ROW, self.MAX_COL)\n",
        "    return self.board\n",
        "\n",
        "  def step(self, action):\n",
        "    reward = 0\n",
        "    done = False\n",
        "    # アクション実行後の状態を取得する\n",
        "    self.board, stepNg = GameUtil.fallCoin(self.board, action, self.MY_MARK, self.BLANK_MARK)\n",
        "    if stepNg:\n",
        "      # この列にコインをこれ以上落とせなかった\n",
        "      done = True\n",
        "      reward = -10000\n",
        "      return self.board, reward, done, {}\n",
        "    # 相手の行動を追加する\n",
        "    self.board, stepNg = GameUtil.fallCoin(self.board, GameUtil.enemyPlay(self.board), 2, self.BLANK_MARK)\n",
        "    # ゲームが終了したかどうかを確認する\n",
        "    win = GameUtil.checkEnd(self.board)\n",
        "    if win == self.MY_MARK:\n",
        "      # 自分が勝った\n",
        "      done = True\n",
        "      reward = 1.0\n",
        "    elif win != self.BLANK_MARK:\n",
        "      # 相手が勝った\n",
        "      done = True\n",
        "      reward = -1\n",
        "    return self.board, reward, done, {}\n",
        "\n",
        "  def render(self, mode='console', close=False):\n",
        "    GameUtil.render(self.board, self.MY_MARK, self.BLANK_MARK)\n",
        "\n",
        "  def initState(self):\n",
        "    \"\"\" 盤面を初期化する\n",
        "\n",
        "    Returns:\n",
        "        list: 初期化された盤面の2次元配列\n",
        "    \"\"\"\n",
        "    return [[self.BLANK_MARK] * self.MAX_COL for i in range(self.MAX_ROW)]"
      ],
      "metadata": {
        "id": "0FCO6nEl-JUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training\n",
        "\n",
        "指定回数反復学習し、結果をモデルファイルとして保存する"
      ],
      "metadata": {
        "id": "fRpFC07gAbQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3.7\n",
        "env = Con4()\n",
        "\n",
        "# モデルの生成\n",
        "#  verbose：ログの詳細表示(0:ログなし、1:訓練情報を表示、2:TensorFlowログを表示)\n",
        "model = PPO(MlpPolicy, env, verbose=0, tensorboard_log='./log/con4')\n",
        "# model = PPO2(MlpPolicy, env, verbose=0)\n",
        "# モデルの学習\n",
        "sample = 20000\n",
        "model.learn(total_timesteps=sample)\n",
        "# モデルの保存\n",
        "model.save('con4_model_' + str(sample))\n",
        "\n",
        "print('training end', sample)\n"
      ],
      "metadata": {
        "id": "MG_6nKUz-NJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学習結果の確認\n",
        "\n",
        "Tensorboard を使用して、学習の様子を確認します。\\\n",
        "パラメータや報酬ロジックを変更した際には違いを確認し、より強いAIになるよう調整しましょう\n"
      ],
      "metadata": {
        "id": "enTs9fYtAgSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=./log/con4"
      ],
      "metadata": {
        "id": "DyZXgrkd-T2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AIのテスト\n",
        "\n",
        "作ったAIが想定通りに動くか、まずはコンソールで試してみましょう"
      ],
      "metadata": {
        "id": "yyO3peO2Am0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state = GameUtil.resetState(6, 7)\n",
        "i = 0\n",
        "\n",
        "while True:\n",
        "  i += 1\n",
        "  action, _ = model.predict(state)\n",
        "  state, done = GameUtil.fallCoin(state, action)\n",
        "  if done:\n",
        "    GameUtil.render(state)\n",
        "    break\n",
        "  done = GameUtil.checkEnd(state)\n",
        "  print('done2:', done)\n",
        "  if done != 0:\n",
        "    print('end: ', i)\n",
        "    break\n",
        "\n",
        "  GameUtil.render(state)\n",
        "  if done != 0:\n",
        "    print('win ai: ', i)\n",
        "    break\n",
        "  print('AI action:', done, action)\n",
        "  action = input('input action > ')\n",
        "  state, done = GameUtil.fallCoin(state, int(action), mark = 2)\n",
        "  if done:\n",
        "    print('failed fall: ', action)\n",
        "    GameUtil.render(state)\n",
        "    break\n",
        "  done = GameUtil.checkEnd(state)\n",
        "  if done != 0:\n",
        "    print('win player: ', i)\n",
        "    break"
      ],
      "metadata": {
        "id": "GYFdCNqt-V1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### WebSocket準備\n",
        "\n",
        "ゲーム画面と連携するため、WebSocketの準備をします\\\n",
        "このプログラムは変更しないでください。"
      ],
      "metadata": {
        "id": "oRrULAXWts-5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install websocket-client --quiet"
      ],
      "metadata": {
        "id": "uBj5g2P0tydu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import websocket\n",
        "import json\n",
        "try:\n",
        "    import thread\n",
        "except ImportError:\n",
        "    import _thread as thread\n",
        "import time\n",
        "\n",
        "class Websocket_Client():\n",
        "    isLogin = False\n",
        "    userNo = -1\n",
        "\n",
        "    def __init__(self, host_addr):\n",
        "\n",
        "        # デバックログの表示/非表示設定\n",
        "        websocket.enableTrace(True)\n",
        "\n",
        "        # WebSocketAppクラスを生成\n",
        "        # 関数登録のために、ラムダ式を使用\n",
        "        self.ws = websocket.WebSocketApp(host_addr,\n",
        "            on_message = lambda ws, msg: self.on_message(ws, msg),\n",
        "            on_error   = lambda ws, msg: self.on_error(ws, msg),\n",
        "            on_close   = lambda ws: self.on_close(ws))\n",
        "        self.ws.on_open = lambda ws: self.on_open(ws)\n",
        "\n",
        "    # メッセージ受信に呼ばれる関数\n",
        "    def on_message(self, ws, message):\n",
        "        print(\"### receive : {}\".format(message))\n",
        "        sendData = {}\n",
        "        msg = json.loads(message)\n",
        "        if msg['call'] == 'reload':\n",
        "            print('+++++ reload')\n",
        "            if self.isLogin:\n",
        "                print('+++ Logedin reload')\n",
        "            elif 'player' in msg:\n",
        "                print('ゲームが進行中です。想定外の場合はゲーム画面からゲーム終了ボタンを押してください。')\n",
        "                self.ws.close()\n",
        "                return\n",
        "            elif 'user0' in msg:\n",
        "                print('先攻のユーザがログイン中です。後攻で参加します。')\n",
        "                sendData['user1'] = AI_NAME # input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "                self.userNo = '1'\n",
        "            elif 'user1' in msg:\n",
        "                print('後攻のユーザがログイン中です。先攻で参加します。')\n",
        "                sendData['user0'] = AI_NAME # input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "                self.userNo = '0'\n",
        "            else:\n",
        "                self.userNo = input('先攻で参加する場合は0, 後攻で参加する場合は1を入力 > ')\n",
        "                sendData['user'+self.userNo] = AI_NAME # input('ユーザ名を入力してください >')\n",
        "                sendData['call'] = 'login'\n",
        "                self.isLogin = True\n",
        "        elif msg['call'] == 'step':\n",
        "            print('+++++ step' + str(msg['player']))\n",
        "            state = GameUtil.stdinToState(msg['stdin'])\n",
        "            GameUtil.render(state)\n",
        "            if self.isLogin == False:\n",
        "                print('ゲームが進行中です。想定外の場合はゲーム画面からゲーム終了ボタンを押してください。')\n",
        "                self.ws.close()\n",
        "                return\n",
        "            if self.userNo == str(msg['player']):\n",
        "                print('action start')\n",
        "                sendData['call'] = 'step'\n",
        "                sendData['stdin'] = msg['stdin']\n",
        "                sendData['player'] = self.userNo\n",
        "                # 手動で入力する場合\n",
        "                # sendData['stdout'] = input('next action >')\n",
        "                action, _ = model.predict(state)\n",
        "                sendData['stdout'] = int(action)\n",
        "            else:\n",
        "                print('skip action')\n",
        "                return\n",
        "        elif msg['call'] == 'login':\n",
        "            print('+++++ login')\n",
        "            return\n",
        "        elif msg['call'] == 'end':\n",
        "            print('+++++ end', msg['message'])\n",
        "            GameUtil.render(GameUtil.stdinToState(msg['stdin']))\n",
        "            self.ws.close()\n",
        "            return\n",
        "        else:\n",
        "            print('+++++ unknown call', msg['call'])\n",
        "            return\n",
        "\n",
        "        if 'call' in sendData:\n",
        "            self.sendJson(sendData)\n",
        "            \n",
        "\n",
        "    # エラー時に呼ばれる関数\n",
        "    def on_error(self, ws, error):\n",
        "        print(error)\n",
        "\n",
        "    # サーバーから切断時に呼ばれる関数\n",
        "    def on_close(self, ws):\n",
        "        print(\"### closed ###\")\n",
        "\n",
        "    # サーバーから接続時に呼ばれる関数\n",
        "    def on_open(self, ws):\n",
        "        thread.start_new_thread(self.run, ())\n",
        "        print('+++ start new thread end');\n",
        "        time.sleep(1)\n",
        "        self.sendJson({'call': 'reload'})\n",
        "\n",
        "    # サーバーから接続時にスレッドで起動する関数\n",
        "    def run(self, *args):\n",
        "        while True:\n",
        "            time.sleep(0.1)\n",
        "            # input_data = input(\"send data:\") \n",
        "            # self.ws.send(input_data)\n",
        "    \n",
        "        self.ws.close()\n",
        "        print(\"thread terminating...\")\n",
        "    def sendJson(self, data):\n",
        "        print('### send:', data)\n",
        "        self.ws.send(json.dumps(data))\n",
        "\n",
        "    # websocketクライアント起動\n",
        "    def run_forever(self):\n",
        "        self.ws.run_forever()\n",
        "\n"
      ],
      "metadata": {
        "id": "tqTh76MMt1Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### プレイ\n",
        "\n",
        "[ゲーム画面](https://www.tomiko.cf/red/con4/room/demo-a.html) を開いて、作ったAIと対戦してみよう！"
      ],
      "metadata": {
        "id": "X_YUWmzgtxp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AI_NAME = \"テストAI\"\n",
        "HOST_ADDR = \"wss://www.tomiko.cf/red/api/con4/demo-a\"\n",
        "ws_client = Websocket_Client(HOST_ADDR)\n",
        "ws_client.run_forever()\n"
      ],
      "metadata": {
        "id": "nukJTGkquAlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### より強いAIを作るには\n",
        "\n",
        "移動ゲームと違って、コネクトフォーのAIでは考えることがたくさんあります。\n",
        "\n",
        "* 報酬は？\n",
        "\n",
        "上のサンプルでは、勝った場合・負けた場合のみ報酬を与えましたが、最終結果だけを見るのではなく、例えばリーチになった場合や、相手のリーチを阻止した・見逃した場合など、いろいろなパターンで報酬を与えるべきです。\\\n",
        "どのパターンでどれだけの報酬を与えるのがいいか、いろいろ試してみましょう。\n",
        "\n",
        "* 学習回数は？\n",
        "\n",
        "手っ取り早く強いAIにするために、学習回数を多くしたいところですが、例えば100万回、1000万回で試してみると、過学習というものが具体的にどんな現象かわかりやすいと思います。\\\n",
        "(Google Colabで動かない場合は、ローカルPCなどで試してみましょう) \\\n",
        "対戦形式のAIでは、過学習による悪影響がわかりやすく出やすいので、どうすればそれを防げるか（学習パターンの改善）考えてみましょう\n",
        "\n",
        "* アルゴリズムやパラメータは？\n",
        "\n",
        "移動ゲームの説明であったように、報酬の計算方法に合わせてパラメータを変更してみましょう。\\\n",
        "また、今回使用した PPO2 / MlpPolicy は汎用性が高いので、とりあえずで使うのにはちょうどいいですが、複雑なパターンのばあいはACKTR を使ってみたり\\\n",
        "あるいは機械学習ではなく [模倣学習(GAIL)](https://note.com/npaka/n/n2289ad7f4a3e) を使ってみるのも面白いかもしれません。\n"
      ],
      "metadata": {
        "id": "_l8dfpzBuMgV"
      }
    }
  ]
}